# This file contains the complete list of options in the main script.
# It must contain at least a root menu with several options, and a description
# of each option in the root menu.
# Each option in any menu should have a description

# ROOT MENU
root:
  options: 
    # - create   <Some true options may be missed because the appropriate one
    # - load      may have been selected by the starting command> 
    - setup
    - load_corpus
    - get_labels
    - load_labels
    - reset_labels
    - PU_learning
    - get_feedback_options
    - update_model
    - import_export_annotations
    - inference

# In the following, each menu option is described.
# GENERIC FORMAT OF AN OPTION DESCRIPTOR:
# optionName:
#   title: <Here, the text describing the option, that will be shown to user>
#   options: <Contains the list of submenu options>
#     <The list of options can be a simple list:>
#     - option
#     - option
#     - ...
#     <In this case, each option specifies a task to be done by the task
#      manager, or a node of the navigation tree, that will be followed by
#      further list of options>
#     <Alternatively, options may contain a list of single-key dicts. This
#      happens when the task has been already selected, but some input
#      arguments are needed.
#      The single key of each dictionary specifes the way to get the input
#      arguments. There are thres possible ways: >
#     <1: 'parameters': in that case, the options are defined in another
#                      dictionary, where the keys are the input arguments and
#                      the values describe the meaning of the input argument>
#     - parameters:
#         param0: description
#         param1: description
#         ...
#     <2: 'path': the input argument is one of the folder or file names
#                 in the path specified in paths2data[name], where paths2data
#                 is one the dictionaries required to create a MenuNavigator
#                 object>
#     - path: name
#     <3: 'get_method': the possible values of the input argument are computed
#                       by the specified method 'name' defined in the task
#                       TaskManager class>
#     - get_method: name
#   post_opt: <Specify the list of options that will be activated after
#              executing the selected task>
#     - option
#     - option
#     - option

# ##########################
# OPTIONS FROM THE ROOT MENU
# For each option in the root menu, some info must be provided.
# Note, also, that specific informacion can be provided about options that do
# not appear in the root menu, but may be selected from the starting command
# from the main script.
create:
  title: Create new project
  post_opts:
    - setup

setup:
  title: Activate configuration file

load:
  title: Load existing project

load_corpus:
  title: Load corpus (to be done only once. Corpus cannot be changed)
  options:
    - get_method: _get_corpus_list

get_labels:
  title: Select a preliminary subcorpus from the positive class
  options:
    - import_AI_subcorpus
    - get_labels_by_keywords
    - analyze_keywords
    - get_labels_by_topics
    - get_labels_by_zeroshot
    - evaluate_PUlabels

load_labels:
  title: Load models
  options:
    - get_method: _get_dataset_list

reset_labels:
  title: Reset models
  options:
    - get_method: _get_dataset_list

PU_learning:
  title: PU learning
  options:
    - train_PUmodel
    - evaluate_PUmodel
    - performance_metrics_PU

get_feedback_options:
  title: Get relevance feedback from user
  options:
    - get_feedback
    - sample_documents
    - get_labels_from_docs
    - annotate

update_model: 
  title: Update the classifier model with the latest relevance feedback
  options:
    - retrain_model
    - reevaluate_model
    - performance_metrics_PN

import_export_annotations:
  title: Import / export annotations
  options:
    - import_annotations
    - export_annotations

inference:
  title: Apply inference over precomputed embeddings (if available, only)
  #options:
  #  - get_method: _get_inference
    
# ######################
# Options for get_labels
import_AI_subcorpus:
    title: Import labels from a source file

get_labels_by_keywords:
    title: Get subcorpus from a given list of keywords

analyze_keywords:
    title: Analyze the presence of selected keywords in the corpus

get_labels_by_topics:
    title: Get subcorpus from a topic selection function

get_labels_by_zeroshot:
    title: Get subcorpus from a category name

evaluate_PUlabels:
    title: Evaluate subcorpus with respect to a gold standard
    options:
      - get_method: _get_gold_standard_labels

# #######################
# Options for PU_learning

train_PUmodel:
  title: Train PU classifier model with the available labels

evaluate_PUmodel:
  title: Evaluate PU classifier model with the available labels
  options:
    - parameters:
        train_test: Evaluate samples used for training and test only
        all: Evaluate all samples in the local dataset

performance_metrics_PU:
  title: Show all performance metrics

# ################################
# Options for get_feedback_options

get_feedback:
  title: (All in one step) Sample documents, get labels and annotate
  options:
    - parameters:
        random: Random sampling over the test-train split, for retraining
        least_confidence: Least confidence over the test-train split, for retraining
        extremes: Sampling biased towards confident predictions, for retraining
        full_rs: Fully random sampling over the whole dataset, for testing

sample_documents:
  title: Sample documents for annotation
  options:
    - parameters:
        random: Random sampling over the test-train split, for retraining
        least_confidence: Least confidence over the test-train split, for retraining
        extremes: Sampling biased towards confident predictions, for retraining
        full_rs: Fully random sampling over the whole dataset, for testing

get_labels_from_docs:
  title: Query labels from user

annotate:
  title: Annotate documents with the user-provided labels

# ########################
# Options for update_model
retrain_model:
  title: Retrain model with manual annotations

reevaluate_model:
  title: Evaluate retrained model.
  options:
    - parameters:
        train_test: Evaluate samples used for training and test only
        all: Evaluate all samples in the local dataset

performance_metrics_PN:
  title: Show all performance metrics


# ########################
# Options for import_export_annotations
import_annotations:
  title: "Import annotations (overwrites existing annotations)"
  options:
    - get_method: _get_annotation_list

export_annotations:
  title: "Export annotations (warning: deletes older annotation files)"
